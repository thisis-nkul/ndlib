# WAY FORWARD (aKa TO-DO, do do do do do do)

- integrate loss with SimpleNN class

- implement Adam optimizer, momentum and RMSProp

- add more activation functions in functional such as leaky_relu, tanh, etc.

- implement backprop :zipper_mouth_face:

- All activations and initializations are assumed to be passed as string,
    in future versions let user pass a function or a string of name of function.